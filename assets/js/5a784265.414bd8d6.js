"use strict";(self.webpackChunkkafka_training=self.webpackChunkkafka_training||[]).push([[1877],{8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var s=r(6540);const t={},a=s.createContext(t);function i(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),s.createElement(a.Provider,{value:n},e.children)}},9048:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>u,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"producer-consumer-separation","title":"S\xe9parer Producteur et Consommateur Kafka","description":"Ce document explique comment s\xe9parer la logique de production et de consommation dans des classes Java d\xe9di\xe9es.","source":"@site/docs/02-producer-consumer-separation.md","sourceDirName":".","slug":"/producer-consumer-separation","permalink":"/kafka-training/docs/producer-consumer-separation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/02-producer-consumer-separation.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"S\xe9parer Producteur et Consommateur Kafka","description":"Ce document explique comment s\xe9parer la logique de production et de consommation dans des classes Java d\xe9di\xe9es."},"sidebar":"tutorialSidebar","previous":{"title":"Mise en place de Kafka avec Testcontainers","permalink":"/kafka-training/docs/setup-local-kafka"},"next":{"title":"Tutorial - Basics","permalink":"/kafka-training/docs/category/tutorial---basics"}}');var t=r(4848),a=r(8453);const i={title:"S\xe9parer Producteur et Consommateur Kafka",description:"Ce document explique comment s\xe9parer la logique de production et de consommation dans des classes Java d\xe9di\xe9es."},o="\ud83d\udce6 Refactor : Producteur et Consommateur Kafka r\xe9utilisables",u={},c=[{value:"\ud83c\udfaf Objectif",id:"-objectif",level:2},{value:"Ce qu&#39;on va couvrir :",id:"ce-quon-va-couvrir-",level:2},{value:"\ud83e\udde0 Contexte de d\xe9part",id:"-contexte-de-d\xe9part",level:2},{value:"\ud83d\udee0\ufe0f Cr\xe9ation du <code>KafkaProducerService</code>",id:"\ufe0f-cr\xe9ation-du-kafkaproducerservice",level:2},{value:"\ud83d\udee0\ufe0f Cr\xe9ation du KafkaConsumerService",id:"\ufe0f-cr\xe9ation-du-kafkaconsumerservice",level:2},{value:"\ud83e\uddea Nouveau test d\u2019int\xe9gration : KafkaIntegrationTest",id:"-nouveau-test-dint\xe9gration--kafkaintegrationtest",level:2},{value:"\xc9tapes du test :",id:"\xe9tapes-du-test-",level:3},{value:"\ud83d\udd0d R\xe9sultat console",id:"-r\xe9sultat-console",level:3},{value:"\u2705 Ce que tu as appris ici",id:"-ce-que-tu-as-appris-ici",level:2},{value:"\ud83d\udcda \xc0 suivre",id:"-\xe0-suivre",level:2},{value:"\u270d\ufe0f \xc0 faire toi-m\xeame (exercice)",id:"\ufe0f-\xe0-faire-toi-m\xeame-exercice",level:2}];function l(e){const n={blockquote:"blockquote",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"-refactor--producteur-et-consommateur-kafka-r\xe9utilisables",children:"\ud83d\udce6 Refactor : Producteur et Consommateur Kafka r\xe9utilisables"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"-objectif",children:"\ud83c\udfaf Objectif"}),"\n",(0,t.jsxs)(n.p,{children:["Dans cette \xe9tape, nous allons am\xe9liorer notre test Kafka en ",(0,t.jsx)(n.strong,{children:"s\xe9parant la logique de production et de consommation"})," dans des ",(0,t.jsx)(n.strong,{children:"classes Java d\xe9di\xe9es"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"ce-quon-va-couvrir-",children:"Ce qu'on va couvrir :"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\u2705 Cr\xe9er un ",(0,t.jsx)(n.code,{children:"KafkaProducerService"})," et un ",(0,t.jsx)(n.code,{children:"KafkaConsumerService"})]}),"\n",(0,t.jsx)(n.li,{children:"\u2705 \xc9crire un test d\u2019int\xe9gration pour v\xe9rifier l\u2019envoi et la r\xe9ception de messages"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Utiliser Awaitility pour attendre la r\xe9ception des messages dans le topic Kafka"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 V\xe9rifier que les messages re\xe7us correspondent \xe0 ceux envoy\xe9s"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Pourquoi ?"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2705 Rendre le code plus lisible et maintenable"}),"\n",(0,t.jsx)(n.li,{children:"\ud83d\udd01 R\xe9utiliser le m\xeame producteur/consommateur dans plusieurs tests"}),"\n",(0,t.jsx)(n.li,{children:"\ud83d\udcd0 Poser les bases pour des tests d'int\xe9gration plus r\xe9alistes"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"-contexte-de-d\xe9part",children:"\ud83e\udde0 Contexte de d\xe9part"}),"\n",(0,t.jsxs)(n.p,{children:["Jusqu'ici, toute la logique \xe9tait dans le test ",(0,t.jsx)(n.code,{children:"KafkaIntegrationTest"}),".",(0,t.jsx)(n.br,{}),"\n","Cela fonctionne\u2026 mais ce n\u2019est pas propre :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Les ",(0,t.jsx)(n.code,{children:"Properties"})," sont dupliqu\xe9es"]}),"\n",(0,t.jsx)(n.li,{children:"On ne peut pas tester s\xe9par\xe9ment la logique du producteur ou du consommateur"}),"\n",(0,t.jsx)(n.li,{children:"Difficile \xe0 maintenir dans un vrai projet"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.h2,{id:"\ufe0f-cr\xe9ation-du-kafkaproducerservice",children:["\ud83d\udee0\ufe0f Cr\xe9ation du ",(0,t.jsx)(n.code,{children:"KafkaProducerService"})]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-java",children:"package com.example.kafka;\n\nimport org.apache.kafka.clients.producer.KafkaProducer;\nimport org.apache.kafka.clients.producer.Producer;\nimport org.apache.kafka.clients.producer.ProducerConfig;\nimport org.apache.kafka.clients.producer.ProducerRecord;\nimport org.apache.kafka.common.serialization.StringSerializer;\n\nimport java.util.Properties;\n\n/**\n * Service responsable de l'envoi de messages Kafka (key et value en String).\n */\npublic class KafkaProducerService {\n    // Classe responsable de l'envoi de messages Kafka avec des cl\xe9s et des valeurs de type String.\n\n    private final String bootstrapServers;\n    // Adresse des serveurs Kafka (bootstrap servers) utilis\xe9e pour se connecter au cluster Kafka.\n\n    public KafkaProducerService(String bootstrapServers) {\n        this.bootstrapServers = bootstrapServers;\n        // Constructeur qui initialise l'adresse des serveurs Kafka.\n    }\n\n    public void send(String topic, String key, String value) {\n        // M\xe9thode pour envoyer un message Kafka \xe0 un topic donn\xe9 avec une cl\xe9 et une valeur.\n\n        Properties props = new Properties();\n        // Cr\xe9ation d'un objet Properties pour configurer le producteur Kafka.\n\n        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        // Configuration de l'adresse des serveurs Kafka (bootstrap servers).\n\n        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n        // Configuration du s\xe9rialiseur pour les cl\xe9s (ici, les cl\xe9s sont des cha\xeenes de caract\xe8res).\n\n        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n        // Configuration du s\xe9rialiseur pour les valeurs (ici, les valeurs sont des cha\xeenes de caract\xe8res).\n\n        try (Producer<String, String> producer = new KafkaProducer<>(props)) {\n            // Cr\xe9ation d'un producteur Kafka avec les propri\xe9t\xe9s configur\xe9es.\n            // Le bloc try-with-resources garantit que le producteur sera ferm\xe9 automatiquement.\n\n            ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);\n            // Cr\xe9ation d'un enregistrement Kafka (message) avec le topic, la cl\xe9 et la valeur sp\xe9cifi\xe9s.\n\n            producer.send(record);\n            // Envoi asynchrone du message au cluster Kafka.\n\n            producer.flush();\n            // Vidage des messages en attente pour s'assurer que le message est bien envoy\xe9 avant de fermer le producteur.\n        }\n    }\n}\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"\ud83d\udca1 Cette classe ne garde pas l'instance du producer, elle cr\xe9e et ferme \xe0 chaque envoi. On peut am\xe9liorer \xe7a plus tard."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f-cr\xe9ation-du-kafkaconsumerservice",children:"\ud83d\udee0\ufe0f Cr\xe9ation du KafkaConsumerService"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-java",children:"package com.example.kafka;\n\nimport org.apache.kafka.clients.consumer.Consumer;\nimport org.apache.kafka.clients.consumer.ConsumerConfig;\nimport org.apache.kafka.clients.consumer.ConsumerRecord;\nimport org.apache.kafka.clients.consumer.ConsumerRecords;\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\nimport org.apache.kafka.common.serialization.StringDeserializer;\n\nimport java.time.Duration;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Properties;\n\n/**\n * Service responsable de la consommation de messages Kafka (key et value en String).\n */\npublic class KafkaConsumerService {\n    // Classe responsable de la consommation de messages Kafka avec des cl\xe9s et des valeurs de type String.\n\n    private final String bootstrapServers;\n    // Adresse des serveurs Kafka (bootstrap servers) utilis\xe9e pour se connecter au cluster Kafka.\n\n    private final String groupId;\n    // Identifiant du groupe de consommateurs Kafka.\n\n    private final Consumer<String, String> consumer;\n    // Instance du consommateur Kafka qui sera utilis\xe9e pour lire les messages.\n\n    public KafkaConsumerService(String bootstrapServers, String groupId) {\n        // Constructeur qui initialise les serveurs Kafka et le groupe de consommateurs.\n\n        this.bootstrapServers = bootstrapServers;\n        // Initialise l'adresse des serveurs Kafka.\n\n        this.groupId = groupId;\n        // Initialise l'identifiant du groupe de consommateurs.\n\n        Properties props = new Properties();\n        // Cr\xe9ation d'un objet Properties pour configurer le consommateur Kafka.\n\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        // Configuration de l'adresse des serveurs Kafka (bootstrap servers).\n\n        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n        // Configuration de l'identifiant du groupe de consommateurs.\n\n        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n        // Active la validation automatique des offsets apr\xe8s consommation des messages.\n\n        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n        // Configure le consommateur pour lire les messages depuis le d\xe9but si aucun offset n'est trouv\xe9.\n\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        // Configure le d\xe9s\xe9rialiseur pour les cl\xe9s (ici, les cl\xe9s sont des cha\xeenes de caract\xe8res).\n\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        // Configure le d\xe9s\xe9rialiseur pour les valeurs (ici, les valeurs sont des cha\xeenes de caract\xe8res).\n\n        this.consumer = new KafkaConsumer<>(props);\n        // Instancie un consommateur Kafka avec les propri\xe9t\xe9s configur\xe9es.\n    }\n\n    public List<ConsumerRecord<String, String>> pollMessages(String topic, Duration timeout) {\n        // M\xe9thode pour r\xe9cup\xe9rer les messages d'un topic Kafka avec un d\xe9lai d'attente sp\xe9cifi\xe9.\n\n        consumer.subscribe(Collections.singletonList(topic));\n        // Abonne le consommateur au topic sp\xe9cifi\xe9.\n\n        ConsumerRecords<String, String> records = consumer.poll(timeout);\n        // R\xe9cup\xe8re les messages du topic avec un d\xe9lai d'attente d\xe9fini.\n\n        List<ConsumerRecord<String, String>> list = new ArrayList<>();\n        // Cr\xe9e une liste pour stocker les messages r\xe9cup\xe9r\xe9s.\n\n        for (ConsumerRecord<String, String> record : records.records(topic)) {\n            // Parcourt les messages r\xe9cup\xe9r\xe9s pour le topic sp\xe9cifi\xe9.\n\n            list.add(record);\n            // Ajoute chaque message \xe0 la liste.\n        }\n\n        return list;\n        // Retourne la liste des messages r\xe9cup\xe9r\xe9s.\n    }\n\n    public void close() {\n        // M\xe9thode pour fermer le consommateur Kafka.\n\n        consumer.close();\n        // Ferme le consommateur pour lib\xe9rer les ressources.\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"-nouveau-test-dint\xe9gration--kafkaintegrationtest",children:"\ud83e\uddea Nouveau test d\u2019int\xe9gration : KafkaIntegrationTest"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-java",children:'package com.example.kafka;\n\nimport org.junit.jupiter.api.Test;\nimport org.testcontainers.containers.KafkaContainer;\nimport org.testcontainers.junit.jupiter.Container;\nimport org.testcontainers.junit.jupiter.Testcontainers;\nimport org.testcontainers.utility.DockerImageName;\n\nimport org.awaitility.Awaitility;\n\nimport java.time.Duration;\nimport java.util.List;\nimport java.util.concurrent.TimeUnit;\n\nimport static org.junit.jupiter.api.Assertions.*;\n\n@Testcontainers\n// Annotation indiquant que cette classe utilise Testcontainers pour g\xe9rer des conteneurs Docker dans les tests.\n\npublic class KafkaIntegrationTest {\n// D\xe9claration de la classe de test pour tester l\'int\xe9gration avec Kafka.\n\n    @Container\n    // Annotation indiquant que ce conteneur Kafka sera g\xe9r\xe9 automatiquement par Testcontainers.\n\n    static KafkaContainer kafka = new KafkaContainer(\n        DockerImageName.parse("confluentinc/cp-kafka:7.2.1")\n                       .asCompatibleSubstituteFor("apache/kafka")\n    );\n    // D\xe9claration d\'un conteneur Kafka bas\xe9 sur l\'image Docker "confluentinc/cp-kafka:7.2.1".\n    // Cette image est utilis\xe9e comme substitut compatible pour Apache Kafka.\n\n    @Test\n    // Annotation indiquant qu\'il s\'agit d\'un test unitaire.\n\n    void testKafkaProducerAndConsumerServices() {\n    // M\xe9thode de test pour v\xe9rifier le fonctionnement des services Kafka Producer et Consumer.\n\n        String topic = "test-topic";\n        // Nom du topic Kafka utilis\xe9 pour le test.\n\n        String key = "key";\n        // Cl\xe9 du message Kafka.\n\n        String value = "value";\n        // Valeur du message Kafka.\n\n        System.out.println("\ud83d\ude80 Lancement du test Kafka avec services producteurs/consommateurs...");\n        // Affiche un message indiquant le d\xe9but du test.\n\n        KafkaProducerService producer = new KafkaProducerService(kafka.getBootstrapServers());\n        // Instancie un service Kafka Producer avec l\'adresse des serveurs Kafka fournie par le conteneur.\n\n        KafkaConsumerService consumer = new KafkaConsumerService(kafka.getBootstrapServers(), "test-group");\n        // Instancie un service Kafka Consumer avec l\'adresse des serveurs Kafka et un groupe de consommateurs.\n\n        System.out.println("\ud83d\udee0\ufe0f  Producteur et consommateur instanci\xe9s");\n        // Affiche un message indiquant que le producteur et le consommateur ont \xe9t\xe9 cr\xe9\xe9s.\n\n        producer.send(topic, key, value);\n        // Envoie un message au topic Kafka avec la cl\xe9 et la valeur sp\xe9cifi\xe9es.\n\n        System.out.println("\ud83d\udce4 Message envoy\xe9 sur le topic : " + topic);\n        // Affiche un message indiquant que le message a \xe9t\xe9 envoy\xe9 au topic.\n\n        System.out.println("\u23f3 Attente de r\xe9ception du message...");\n        // Affiche un message indiquant que le test attend la r\xe9ception du message.\n\n        Awaitility.await()\n                .atMost(10, TimeUnit.SECONDS)\n                // D\xe9finit une dur\xe9e maximale d\'attente de 10 secondes pour que la condition soit remplie.\n\n                .pollInterval(Duration.ofMillis(500))\n                // D\xe9finit un intervalle de 500 millisecondes entre chaque v\xe9rification de la condition.\n\n                .untilAsserted(() -> {\n                    // Ex\xe9cute une v\xe9rification r\xe9p\xe9t\xe9e jusqu\'\xe0 ce que la condition d\xe9finie soit remplie ou que le d\xe9lai maximal soit atteint.\n\n                    List<org.apache.kafka.clients.consumer.ConsumerRecord<String, String>> messages =\n                        consumer.pollMessages(topic, Duration.ofMillis(500));\n                    // R\xe9cup\xe8re les messages du topic Kafka en utilisant le consommateur, avec un d\xe9lai d\'attente de 500 millisecondes.\n\n                    System.out.println("\u2705 Messages re\xe7us : " + messages.size());\n                    // Affiche dans la console le nombre de messages re\xe7us.\n\n                    assertFalse(messages.isEmpty(), "Aucun message re\xe7u !");\n                    // V\xe9rifie que la liste des messages n\'est pas vide. Si elle est vide, le test \xe9choue avec le message "Aucun message re\xe7u !".\n\n                    assertEquals(key, messages.get(0).key(), "Cl\xe9 incorrecte");\n                    // V\xe9rifie que la cl\xe9 du premier message re\xe7u correspond \xe0 la cl\xe9 attendue. Si ce n\'est pas le cas, le test \xe9choue avec le message "Cl\xe9 incorrecte".\n\n                    assertEquals(value, messages.get(0).value(), "Valeur incorrecte");\n                    // V\xe9rifie que la valeur du premier message re\xe7u correspond \xe0 la valeur attendue. Si ce n\'est pas le cas, le test \xe9choue avec le message "Valeur incorrecte".\n                });\n\n        consumer.close();\n        // Ferme le consommateur Kafka pour lib\xe9rer les ressources.\n\n        System.out.println("\ud83e\uddf9 Consommateur ferm\xe9 proprement");\n        // Affiche dans la console que le consommateur a \xe9t\xe9 ferm\xe9 correctement.\n\n        System.out.println("\ud83c\udf89 Test termin\xe9 avec succ\xe8s !");\n        // Affiche dans la console que le test s\'est termin\xe9 avec succ\xe8s.\n    }\n}\n'})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["\ud83d\udca1 On utilise ",(0,t.jsx)(n.code,{children:"pollMessages"})," pour r\xe9cup\xe9rer les messages. On peut am\xe9liorer la gestion des offsets et des erreurs plus tard.",(0,t.jsx)(n.br,{}),"\n","\ud83d\udca1 On peut aussi ajouter des logs pour suivre l'envoi et la r\xe9ception des messages."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"\xe9tapes-du-test-",children:"\xc9tapes du test :"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Lancement d\u2019un conteneur Kafka via Testcontainers"}),"\n",(0,t.jsx)(n.li,{children:"Cr\xe9ation du producteur et du consommateur"}),"\n",(0,t.jsxs)(n.li,{children:["Envoi d\u2019un message ",(0,t.jsx)(n.code,{children:'"key":"value"'})," dans le topic"]}),"\n",(0,t.jsx)(n.li,{children:"Attente (avec Awaitility) que le consommateur le lise"}),"\n",(0,t.jsx)(n.li,{children:"Validation que la cl\xe9 et la valeur sont correctes"}),"\n",(0,t.jsx)(n.li,{children:"Fermeture du consommateur"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-r\xe9sultat-console",children:"\ud83d\udd0d R\xe9sultat console"}),"\n",(0,t.jsxs)(n.p,{children:["Lors de l'ex\xe9cution, tu devrais voir dans la ",(0,t.jsx)(n.strong,{children:"Debug Console"})," de VSCode :"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-plaintext",children:"\ud83d\ude80 Lancement du test Kafka avec services producteurs/consommateurs...\n\ud83d\udee0\ufe0f  Producteur et consommateur instanci\xe9s\n\ud83d\udce4 Message envoy\xe9 sur le topic : test-topic\n\u23f3 Attente de r\xe9ception du message...\n\u2705 Messages re\xe7us : 1\n\ud83e\uddf9 Consommateur ferm\xe9 proprement\n\ud83c\udf89 Test termin\xe9 avec succ\xe8s !\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:'\ud83d\udca1 Si tu vois "Aucun message re\xe7u !" ou "Cl\xe9 incorrecte", c\'est que le test a \xe9chou\xe9. V\xe9rifie que le conteneur Kafka est bien lanc\xe9 et accessible.\n\ud83d\udca1 Pense \xe0 ajouter des logs pour suivre l\'envoi et la r\xe9ception des messages..'}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-ce-que-tu-as-appris-ici",children:"\u2705 Ce que tu as appris ici"}),"\n",(0,t.jsxs)(n.p,{children:["\u2714\ufe0f Comment structurer le code Kafka de mani\xe8re modulaire",(0,t.jsx)(n.br,{}),"\n","\u2714\ufe0f Comment \xe9crire des services simples mais testables",(0,t.jsx)(n.br,{}),"\n","\u2714\ufe0f Comment rendre ton test plus propre, clair, et \xe9volutif"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"-\xe0-suivre",children:"\ud83d\udcda \xc0 suivre"}),"\n",(0,t.jsx)(n.p,{children:"\u2714\ufe0f L'envoi de messages multiples dans un topic Kafka"}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f-\xe0-faire-toi-m\xeame-exercice",children:"\u270d\ufe0f \xc0 faire toi-m\xeame (exercice)"}),"\n",(0,t.jsx)(n.p,{children:"Modifier KafkaProducerService pour permettre l\u2019envoi de plusieurs messages"}),"\n",(0,t.jsx)(n.p,{children:"Ajouter un param\xe8tre pour customiser les s\xe9rializers"}),"\n",(0,t.jsx)(n.p,{children:"\xc9crire un test qui envoie 3 messages et v\xe9rifie leur ordre de r\xe9ception"})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);