---
id: 02-producer-consumer-separation
title: S√©parer Producteur et Consommateur Kafka 
description: Ce document explique comment s√©parer la logique de production et de consommation dans des classes Java d√©di√©es.
---

# üì¶ Refactor : Producteur et Consommateur Kafka r√©utilisables

---

## üéØ Objectif

Dans cette √©tape, nous allons am√©liorer notre test Kafka en **s√©parant la logique de production et de consommation** dans des **classes Java d√©di√©es**.

## Ce qu'on va couvrir :
- ‚úÖ Cr√©er un `KafkaProducerService` et un `KafkaConsumerService`
- ‚úÖ √âcrire un test d‚Äôint√©gration pour v√©rifier l‚Äôenvoi et la r√©ception de messages
- ‚úÖ Utiliser Awaitility pour attendre la r√©ception des messages dans le topic Kafka
- ‚úÖ V√©rifier que les messages re√ßus correspondent √† ceux envoy√©s

Pourquoi ?

- ‚úÖ Rendre le code plus lisible et maintenable
- üîÅ R√©utiliser le m√™me producteur/consommateur dans plusieurs tests
- üìê Poser les bases pour des tests d'int√©gration plus r√©alistes

---

## üß† Contexte de d√©part

Jusqu'ici, toute la logique √©tait dans le test `KafkaIntegrationTest`.  
Cela fonctionne‚Ä¶ mais ce n‚Äôest pas propre :

- Les `Properties` sont dupliqu√©es
- On ne peut pas tester s√©par√©ment la logique du producteur ou du consommateur
- Difficile √† maintenir dans un vrai projet

---

## üõ†Ô∏è Cr√©ation du `KafkaProducerService`

```java
package com.example.kafka;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * Service responsable de l'envoi de messages Kafka (key et value en String).
 */
public class KafkaProducerService {
    // Classe responsable de l'envoi de messages Kafka avec des cl√©s et des valeurs de type String.

    private final String bootstrapServers;
    // Adresse des serveurs Kafka (bootstrap servers) utilis√©e pour se connecter au cluster Kafka.

    public KafkaProducerService(String bootstrapServers) {
        this.bootstrapServers = bootstrapServers;
        // Constructeur qui initialise l'adresse des serveurs Kafka.
    }

    public void send(String topic, String key, String value) {
        // M√©thode pour envoyer un message Kafka √† un topic donn√© avec une cl√© et une valeur.

        Properties props = new Properties();
        // Cr√©ation d'un objet Properties pour configurer le producteur Kafka.

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        // Configuration de l'adresse des serveurs Kafka (bootstrap servers).

        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // Configuration du s√©rialiseur pour les cl√©s (ici, les cl√©s sont des cha√Ænes de caract√®res).

        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // Configuration du s√©rialiseur pour les valeurs (ici, les valeurs sont des cha√Ænes de caract√®res).

        try (Producer<String, String> producer = new KafkaProducer<>(props)) {
            // Cr√©ation d'un producteur Kafka avec les propri√©t√©s configur√©es.
            // Le bloc try-with-resources garantit que le producteur sera ferm√© automatiquement.

            ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
            // Cr√©ation d'un enregistrement Kafka (message) avec le topic, la cl√© et la valeur sp√©cifi√©s.

            producer.send(record);
            // Envoi asynchrone du message au cluster Kafka.

            producer.flush();
            // Vidage des messages en attente pour s'assurer que le message est bien envoy√© avant de fermer le producteur.
        }
    }
}
```
>üí° Cette classe ne garde pas l'instance du producer, elle cr√©e et ferme √† chaque envoi. On peut am√©liorer √ßa plus tard.

## üõ†Ô∏è Cr√©ation du KafkaConsumerService

```java
package com.example.kafka;

import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.Properties;

/**
 * Service responsable de la consommation de messages Kafka (key et value en String).
 */
public class KafkaConsumerService {
    // Classe responsable de la consommation de messages Kafka avec des cl√©s et des valeurs de type String.

    private final String bootstrapServers;
    // Adresse des serveurs Kafka (bootstrap servers) utilis√©e pour se connecter au cluster Kafka.

    private final String groupId;
    // Identifiant du groupe de consommateurs Kafka.

    private final Consumer<String, String> consumer;
    // Instance du consommateur Kafka qui sera utilis√©e pour lire les messages.

    public KafkaConsumerService(String bootstrapServers, String groupId) {
        // Constructeur qui initialise les serveurs Kafka et le groupe de consommateurs.

        this.bootstrapServers = bootstrapServers;
        // Initialise l'adresse des serveurs Kafka.

        this.groupId = groupId;
        // Initialise l'identifiant du groupe de consommateurs.

        Properties props = new Properties();
        // Cr√©ation d'un objet Properties pour configurer le consommateur Kafka.

        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        // Configuration de l'adresse des serveurs Kafka (bootstrap servers).

        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        // Configuration de l'identifiant du groupe de consommateurs.

        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
        // Active la validation automatique des offsets apr√®s consommation des messages.

        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        // Configure le consommateur pour lire les messages depuis le d√©but si aucun offset n'est trouv√©.

        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        // Configure le d√©s√©rialiseur pour les cl√©s (ici, les cl√©s sont des cha√Ænes de caract√®res).

        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        // Configure le d√©s√©rialiseur pour les valeurs (ici, les valeurs sont des cha√Ænes de caract√®res).

        this.consumer = new KafkaConsumer<>(props);
        // Instancie un consommateur Kafka avec les propri√©t√©s configur√©es.
    }

    public List<ConsumerRecord<String, String>> pollMessages(String topic, Duration timeout) {
        // M√©thode pour r√©cup√©rer les messages d'un topic Kafka avec un d√©lai d'attente sp√©cifi√©.

        consumer.subscribe(Collections.singletonList(topic));
        // Abonne le consommateur au topic sp√©cifi√©.

        ConsumerRecords<String, String> records = consumer.poll(timeout);
        // R√©cup√®re les messages du topic avec un d√©lai d'attente d√©fini.

        List<ConsumerRecord<String, String>> list = new ArrayList<>();
        // Cr√©e une liste pour stocker les messages r√©cup√©r√©s.

        for (ConsumerRecord<String, String> record : records.records(topic)) {
            // Parcourt les messages r√©cup√©r√©s pour le topic sp√©cifi√©.

            list.add(record);
            // Ajoute chaque message √† la liste.
        }

        return list;
        // Retourne la liste des messages r√©cup√©r√©s.
    }

    public void close() {
        // M√©thode pour fermer le consommateur Kafka.

        consumer.close();
        // Ferme le consommateur pour lib√©rer les ressources.
    }
}
```

## üß™ Nouveau test d‚Äôint√©gration : KafkaIntegrationTest

```java
package com.example.kafka;

import org.junit.jupiter.api.Test;
import org.testcontainers.containers.KafkaContainer;
import org.testcontainers.junit.jupiter.Container;
import org.testcontainers.junit.jupiter.Testcontainers;
import org.testcontainers.utility.DockerImageName;

import org.awaitility.Awaitility;

import java.time.Duration;
import java.util.List;
import java.util.concurrent.TimeUnit;

import static org.junit.jupiter.api.Assertions.*;

@Testcontainers
// Annotation indiquant que cette classe utilise Testcontainers pour g√©rer des conteneurs Docker dans les tests.

public class KafkaIntegrationTest {
// D√©claration de la classe de test pour tester l'int√©gration avec Kafka.

    @Container
    // Annotation indiquant que ce conteneur Kafka sera g√©r√© automatiquement par Testcontainers.

    static KafkaContainer kafka = new KafkaContainer(
        DockerImageName.parse("confluentinc/cp-kafka:7.2.1")
                       .asCompatibleSubstituteFor("apache/kafka")
    );
    // D√©claration d'un conteneur Kafka bas√© sur l'image Docker "confluentinc/cp-kafka:7.2.1".
    // Cette image est utilis√©e comme substitut compatible pour Apache Kafka.

    @Test
    // Annotation indiquant qu'il s'agit d'un test unitaire.

    void testKafkaProducerAndConsumerServices() {
    // M√©thode de test pour v√©rifier le fonctionnement des services Kafka Producer et Consumer.

        String topic = "test-topic";
        // Nom du topic Kafka utilis√© pour le test.

        String key = "key";
        // Cl√© du message Kafka.

        String value = "value";
        // Valeur du message Kafka.

        System.out.println("üöÄ Lancement du test Kafka avec services producteurs/consommateurs...");
        // Affiche un message indiquant le d√©but du test.

        KafkaProducerService producer = new KafkaProducerService(kafka.getBootstrapServers());
        // Instancie un service Kafka Producer avec l'adresse des serveurs Kafka fournie par le conteneur.

        KafkaConsumerService consumer = new KafkaConsumerService(kafka.getBootstrapServers(), "test-group");
        // Instancie un service Kafka Consumer avec l'adresse des serveurs Kafka et un groupe de consommateurs.

        System.out.println("üõ†Ô∏è  Producteur et consommateur instanci√©s");
        // Affiche un message indiquant que le producteur et le consommateur ont √©t√© cr√©√©s.

        producer.send(topic, key, value);
        // Envoie un message au topic Kafka avec la cl√© et la valeur sp√©cifi√©es.

        System.out.println("üì§ Message envoy√© sur le topic : " + topic);
        // Affiche un message indiquant que le message a √©t√© envoy√© au topic.

        System.out.println("‚è≥ Attente de r√©ception du message...");
        // Affiche un message indiquant que le test attend la r√©ception du message.

        Awaitility.await()
                .atMost(10, TimeUnit.SECONDS)
                // D√©finit une dur√©e maximale d'attente de 10 secondes pour que la condition soit remplie.

                .pollInterval(Duration.ofMillis(500))
                // D√©finit un intervalle de 500 millisecondes entre chaque v√©rification de la condition.

                .untilAsserted(() -> {
                    // Ex√©cute une v√©rification r√©p√©t√©e jusqu'√† ce que la condition d√©finie soit remplie ou que le d√©lai maximal soit atteint.

                    List<org.apache.kafka.clients.consumer.ConsumerRecord<String, String>> messages =
                        consumer.pollMessages(topic, Duration.ofMillis(500));
                    // R√©cup√®re les messages du topic Kafka en utilisant le consommateur, avec un d√©lai d'attente de 500 millisecondes.

                    System.out.println("‚úÖ Messages re√ßus : " + messages.size());
                    // Affiche dans la console le nombre de messages re√ßus.

                    assertFalse(messages.isEmpty(), "Aucun message re√ßu !");
                    // V√©rifie que la liste des messages n'est pas vide. Si elle est vide, le test √©choue avec le message "Aucun message re√ßu !".

                    assertEquals(key, messages.get(0).key(), "Cl√© incorrecte");
                    // V√©rifie que la cl√© du premier message re√ßu correspond √† la cl√© attendue. Si ce n'est pas le cas, le test √©choue avec le message "Cl√© incorrecte".

                    assertEquals(value, messages.get(0).value(), "Valeur incorrecte");
                    // V√©rifie que la valeur du premier message re√ßu correspond √† la valeur attendue. Si ce n'est pas le cas, le test √©choue avec le message "Valeur incorrecte".
                });

        consumer.close();
        // Ferme le consommateur Kafka pour lib√©rer les ressources.

        System.out.println("üßπ Consommateur ferm√© proprement");
        // Affiche dans la console que le consommateur a √©t√© ferm√© correctement.

        System.out.println("üéâ Test termin√© avec succ√®s !");
        // Affiche dans la console que le test s'est termin√© avec succ√®s.
    }
}
```
>üí° On utilise `pollMessages` pour r√©cup√©rer les messages. On peut am√©liorer la gestion des offsets et des erreurs plus tard.   
>üí° On peut aussi ajouter des logs pour suivre l'envoi et la r√©ception des messages.

### √âtapes du test :
1. Lancement d‚Äôun conteneur Kafka via Testcontainers
2. Cr√©ation du producteur et du consommateur
3. Envoi d‚Äôun message `"key":"value"` dans le topic
4. Attente (avec Awaitility) que le consommateur le lise
5. Validation que la cl√© et la valeur sont correctes
6. Fermeture du consommateur

### üîç R√©sultat console

Lors de l'ex√©cution, tu devrais voir dans la **Debug Console** de VSCode :

```plaintext
üöÄ Lancement du test Kafka avec services producteurs/consommateurs...
üõ†Ô∏è  Producteur et consommateur instanci√©s
üì§ Message envoy√© sur le topic : test-topic
‚è≥ Attente de r√©ception du message...
‚úÖ Messages re√ßus : 1
üßπ Consommateur ferm√© proprement
üéâ Test termin√© avec succ√®s !
```
>üí° Si tu vois "Aucun message re√ßu !" ou "Cl√© incorrecte", c'est que le test a √©chou√©. V√©rifie que le conteneur Kafka est bien lanc√© et accessible.
>üí° Pense √† ajouter des logs pour suivre l'envoi et la r√©ception des messages..

## ‚úÖ Ce que tu as appris ici
‚úîÔ∏è Comment structurer le code Kafka de mani√®re modulaire    
‚úîÔ∏è Comment √©crire des services simples mais testables   
‚úîÔ∏è Comment rendre ton test plus propre, clair, et √©volutif  

---

## üìö √Ä suivre
‚úîÔ∏è L'envoi de messages multiples dans un topic Kafka

## ‚úçÔ∏è √Ä faire toi-m√™me (exercice)
Modifier KafkaProducerService pour permettre l‚Äôenvoi de plusieurs messages

Ajouter un param√®tre pour customiser les s√©rializers

√âcrire un test qui envoie 3 messages et v√©rifie leur ordre de r√©ception